## HTTP/2.0 등장배경

- HTTP/1.1의 메시지 포맷은 구현의 단순성과 접근성에 주안점을 두고 최적화됨

  → 커넥션 하나를 통해 요청을 하나 보내고 응답 하나를 받음 → latency 이슈 발생

- HOL Blocking (Head Of Line Blocking)
  - 첫 번째 요청이 지연되면 나머지 요청들도 지연됨
- 성능 문제를 해결하기 위해 다양한 프로토콜이 제안됨
  - 로이 필딩의 WAKA 프로토콜
  - MS의 S+M 프로토콜
  - 구글의 SPDY 프로토콜 → HTTP/2.0의 기반이 됨
    - 헤더의 압축으로 대역폭 절약
    - 하나의 TCP에 여러 요청을 동시에 보내서 latency 줄임
    - 클라이언트가 요청을 보내지 않아도 서버가 능동적으로 푸시

## HTTP/2.0의 개요

- 서버와 클라이언트 사이의 TCP 커넥션 위에서 동작 → TCP 커넥션을 초기화하는 것은 클라이언트
- 요청과 응답은 한 개 이상의 프레임에 담김 → HTTP 헤더는 압축됨
  - 스트림을 통해 보내짐 → 하나의 커넥션 위에 여러개의 스트림이 동시에 만들어짐 → 동시 처리 가능
    - 스트림의 흐름 제어와 우선 순위 부여 가능
- 서버 푸시 도입
  - 요청을 명시적으로 받지 않더라도 능동적으로 클라이언트에게 응답 가능
- HTTP/1.1과 요청/응답 메시지가 같도록 유지

## HTTP/1.1과의 차이점

### 프레임

- 모든 메시지가 프레임에 담겨서 전송

### 스트림과 멀티플렉싱

**스트림**

- HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에서 교환되는 프레임들의 양방향 시퀀스
  - 한 쌍의 요청과 응답은 하나의 스트림을 통해 이루어짐
  - 요청을 주고 받으면 스트림이 닫힘

**멀티플랙싱**

- 하나의 커넥션에 여러개의 스트림을 동시에 여는 것

### 헤더 압축

- HTTP/1.1에서는 헤더를 압축없이 전송

  - HTTP/1.1이 나왔던 1997년도보다 현재 한 웹사이트에 많은 리소스를 소모하게 됨

    → 많은 요청을 주고 받을 수 밖에 없기 때문에 latency가 생길 수 밖에 없음

- 헤더를 [HPACK](https://datatracker.ietf.org/doc/html/rfc7541) 명세에 정의된 헤더 압축 방법으로 압축하여 ‘헤더 블록 조각’들로 쪼개져서  전송

  - 받는 쪽에서는 이 조각들을 이어서 압축을 풀어 원래의 헤더 집합으로 복원

### 서버 푸시

- 하나의 요청에 대해 응답으로 여러개의 리소스를 반환
  - 트레픽과 latency 감소